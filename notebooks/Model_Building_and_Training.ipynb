{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import mlflow\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mlflow Autologging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable MLflow autologging \n",
    "mlflow.pytorch.autolog()\n",
    "mlflow.sklearn.autolog(log_models=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the merged fraud data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "      <th>transaction_count</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>purchase_value_scaled</th>\n",
       "      <th>source_Direct</th>\n",
       "      <th>source_SEO</th>\n",
       "      <th>...</th>\n",
       "      <th>country_United States</th>\n",
       "      <th>country_Uruguay</th>\n",
       "      <th>country_Uzbekistan</th>\n",
       "      <th>country_Vanuatu</th>\n",
       "      <th>country_Venezuela</th>\n",
       "      <th>country_Viet Nam</th>\n",
       "      <th>country_Virgin Islands (U.S.)</th>\n",
       "      <th>country_Yemen</th>\n",
       "      <th>country_Zambia</th>\n",
       "      <th>country_Zimbabwe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.549607</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.197335</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>0.385831</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0.986342</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.767974</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   purchase_value  sex   age  class  transaction_count  hour_of_day  \\\n",
       "0            47.0    0  30.0    0.0                  1            3   \n",
       "1            15.0    0  34.0    0.0                  1           20   \n",
       "2            44.0    1  29.0    0.0                  1           23   \n",
       "3            55.0    0  30.0    0.0                  1           16   \n",
       "4            51.0    0  37.0    0.0                  1            4   \n",
       "\n",
       "   day_of_week  purchase_value_scaled  source_Direct  source_SEO  ...  \\\n",
       "0            6               0.549607          False        True  ...   \n",
       "1            2              -1.197335          False        True  ...   \n",
       "2            5               0.385831          False       False  ...   \n",
       "3            5               0.986342           True       False  ...   \n",
       "4            1               0.767974          False        True  ...   \n",
       "\n",
       "   country_United States  country_Uruguay  country_Uzbekistan  \\\n",
       "0                  False            False               False   \n",
       "1                  False            False               False   \n",
       "2                  False            False               False   \n",
       "3                  False            False               False   \n",
       "4                  False            False               False   \n",
       "\n",
       "   country_Vanuatu  country_Venezuela  country_Viet Nam  \\\n",
       "0            False              False             False   \n",
       "1            False              False             False   \n",
       "2            False              False             False   \n",
       "3            False              False             False   \n",
       "4            False              False             False   \n",
       "\n",
       "   country_Virgin Islands (U.S.)  country_Yemen  country_Zambia  \\\n",
       "0                          False          False           False   \n",
       "1                          False          False           False   \n",
       "2                          False          False           False   \n",
       "3                          False          False           False   \n",
       "4                          False          False           False   \n",
       "\n",
       "   country_Zimbabwe  \n",
       "0             False  \n",
       "1             False  \n",
       "2             False  \n",
       "3             False  \n",
       "4             False  \n",
       "\n",
       "[5 rows x 194 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "credit data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>time_in_days</th>\n",
       "      <th>Amount_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.342584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1.158900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.139886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-0.073813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V23       V24       V25       V26       V27  \\\n",
       "0  0.098698  0.363787  ... -0.110474  0.066928  0.128539 -0.189115  0.133558   \n",
       "1  0.085102 -0.255425  ...  0.101288 -0.339846  0.167170  0.125895 -0.008983   \n",
       "2  0.247676 -1.514654  ...  0.909412 -0.689281 -0.327642 -0.139097 -0.055353   \n",
       "3  0.377436 -1.387024  ... -0.190321 -1.175575  0.647376 -0.221929  0.062723   \n",
       "4 -0.270533  0.817739  ... -0.137458  0.141267 -0.206010  0.502292  0.219422   \n",
       "\n",
       "        V28  Amount  Class  time_in_days  Amount_scaled  \n",
       "0 -0.021053  149.62      0      0.000000       0.244200  \n",
       "1  0.014724    2.69      0      0.000000      -0.342584  \n",
       "2 -0.059752  378.66      0      0.000012       1.158900  \n",
       "3  0.061458  123.50      0      0.000012       0.139886  \n",
       "4  0.215153   69.99      0      0.000023      -0.073813  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the cleaned datasets (from Task 1)\n",
    "fraud_data = pd.read_csv('C:/Users/Administrator/Documents/kifiya/Week_8/clean_data/merged_data.csv')\n",
    "creditcard_data = pd.read_csv('C:/Users/Administrator/Documents/kifiya/Week_8/clean_data/Preprocessed_Creditcard_Data.csv')\n",
    "\n",
    "# Drop unnecessary columns for training\n",
    "fraud_data = fraud_data.drop(columns=['signup_time', 'purchase_time', 'user_id', 'device_id', \n",
    "                                      'ip_address', 'lower_bound_ip_address', 'upper_bound_ip_address'], errors='ignore')\n",
    "\n",
    "print('The Merged fraud data')\n",
    "display(fraud_data.head())\n",
    "print('credit data')\n",
    "display(creditcard_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 14:12:46 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '38faa4d05523462aa5f0f8db227604d6', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2024/10/26 14:12:46 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "2024/10/26 14:12:46 WARNING mlflow.sklearn: Failed to infer model signature: the trained model does not have a `predict` or `transform` function, which is required in order to infer the signature\n",
      "2024/10/26 14:12:46 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2024/10/26 14:12:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/26 14:12:55 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '874d2a03dc894ef599f448fe36fcf000', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2024/10/26 14:12:55 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "2024/10/26 14:12:55 WARNING mlflow.sklearn: Failed to infer model signature: the trained model does not have a `predict` or `transform` function, which is required in order to infer the signature\n",
      "2024/10/26 14:12:55 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2024/10/26 14:12:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "# Separate features and targets for Fraud Data\n",
    "X_fraud = fraud_data.drop(columns=['class'])  # Feature set\n",
    "y_fraud = fraud_data['class']  # Target\n",
    "\n",
    "# Separate features and targets for Credit Card Data\n",
    "X_credit = creditcard_data.drop(columns=['Class'])  # Feature set\n",
    "y_credit = creditcard_data['Class']  # Target\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_fraud, y_fraud = smote.fit_resample(X_fraud, y_fraud)\n",
    "X_credit, y_credit = smote.fit_resample(X_credit, y_credit)\n",
    "\n",
    "#for scikit-learn models\n",
    "y_credit_sci=y_credit.values.ravel()\n",
    "y_fraud_sci=y_fraud.values.ravel()\n",
    "X_fraud_sci=X_fraud\n",
    "X_credit_sci=X_credit\n",
    "\n",
    "\n",
    "\n",
    "# Train-Test Split for both datasets\n",
    "X_fraud_train, X_fraud_test, y_fraud_train, y_fraud_test = train_test_split(X_fraud, y_fraud, test_size=0.25, random_state=42)\n",
    "X_credit_train, X_credit_test, y_credit_train, y_credit_test = train_test_split(X_credit, y_credit, test_size=0.25, random_state=42)\n",
    "\n",
    "# train split for scikit_learn models\n",
    "X_fraud_train_sci, X_fraud_test_sci, y_fraud_train_sci, y_fraud_test_sci = train_test_split(X_fraud_sci, y_fraud_sci, test_size=0.25, random_state=42)\n",
    "X_credit_train_sci, X_credit_test_sci, y_credit_train_sci, y_credit_test_sci = train_test_split(X_credit_sci, y_credit_sci, test_size=0.25, random_state=42)\n",
    "\n",
    "# Normalize the data (Standard Scaling)\n",
    "scaler = StandardScaler()\n",
    "X_fraud_train = scaler.fit_transform(X_fraud_train)\n",
    "X_fraud_test = scaler.transform(X_fraud_test)\n",
    "X_credit_train = scaler.fit_transform(X_credit_train)\n",
    "X_credit_test = scaler.transform(X_credit_test)\n",
    "\n",
    "# Convert the datasets into PyTorch tensors\n",
    "X_fraud_train_tensor = torch.tensor(X_fraud_train, dtype=torch.float32)\n",
    "y_fraud_train_tensor = torch.tensor(y_fraud_train.values, dtype=torch.float32)\n",
    "X_fraud_test_tensor = torch.tensor(X_fraud_test, dtype=torch.float32)\n",
    "y_fraud_test_tensor = torch.tensor(y_fraud_test.values, dtype=torch.float32)\n",
    "\n",
    "X_credit_train_tensor = torch.tensor(X_credit_train, dtype=torch.float32)\n",
    "y_credit_train_tensor = torch.tensor(y_credit_train.values, dtype=torch.float32)\n",
    "X_credit_test_tensor = torch.tensor(X_credit_test, dtype=torch.float32)\n",
    "y_credit_test_tensor = torch.tensor(y_credit_test.values, dtype=torch.float32)\n",
    "\n",
    "# DataLoader for batching\n",
    "batch_size = 16\n",
    "train_loader_fraud = torch.utils.data.DataLoader(TensorDataset(X_fraud_train_tensor, y_fraud_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "test_loader_fraud = torch.utils.data.DataLoader(TensorDataset(X_fraud_test_tensor, y_fraud_test_tensor), batch_size=batch_size)\n",
    "\n",
    "train_loader_credit = torch.utils.data.DataLoader(TensorDataset(X_credit_train_tensor, y_credit_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "test_loader_credit = torch.utils.data.DataLoader(TensorDataset(X_credit_test_tensor, y_credit_test_tensor), batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Early stop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping mechanism\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = loss\n",
    "        elif loss > self.best_loss + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = loss\n",
    "            self.counter = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definitions (MLP, CNN, RNN, LSTM)\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size=32, batch_first=True)\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add sequence dimension\n",
    "        h0 = torch.zeros(1, x.size(0), 32)  # Initial hidden state\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = torch.sigmoid(self.fc(out[:, -1, :]))\n",
    "        return out\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size=32, batch_first=True)\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add sequence dimension\n",
    "        h0 = torch.zeros(1, x.size(0), 32)  # Initial hidden state\n",
    "        c0 = torch.zeros(1, x.size(0), 32)  # Initial cell state\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = torch.sigmoid(self.fc(out[:, -1, :]))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ML models function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scikit-learn classifiers\n",
    "def train_sklearn_model(model, X_train, y_train):\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trian DL models function with MLflow tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with MLflow tracking\n",
    "def train_model(model, train_loader, optimizer, criterion, num_epochs=15, patience=3, model_name=\"model\"):\n",
    "    early_stopper = EarlyStopping(patience=patience)\n",
    "    model.train()\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss = 0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                optimizer.zero_grad()  # Clear gradients\n",
    "                y_pred = model(X_batch).squeeze()  # Forward pass\n",
    "                loss = criterion(y_pred, y_batch)  # Compute loss\n",
    "                loss.backward()  # Backward pass\n",
    "                optimizer.step()  # Update weights\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            avg_loss = total_loss / len(train_loader)\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "            \n",
    "            # Log loss for each epoch\n",
    "            mlflow.log_metric('loss', avg_loss, step=epoch)\n",
    "\n",
    "            # Early stopping\n",
    "            early_stopper(avg_loss)\n",
    "            if early_stopper.early_stop:\n",
    "                print(\"Early stopping triggered!\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate DL models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "# Updated PyTorch model evaluation function\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            y_pred = model(X_batch).squeeze()\n",
    "            preds = (y_pred > 0.5).float()  # Convert probabilities to 0/1\n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_labels.extend(y_batch.numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate ML models with MLflow Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sklearn_model(model, X_test, y_test, model_name):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Get predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='macro')\n",
    "        recall = recall_score(y_test, y_pred, average='macro')\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "        # Log metrics to MLflow\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "        # Print metrics\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models for both fraud and credit datasets\n",
    "input_size_fraud = X_fraud_train.shape[1]\n",
    "input_size_credit = X_credit_train.shape[1]\n",
    "\n",
    "mlp_model_fraud = MLPModel(input_size_fraud)\n",
    "cnn_model_fraud = CNNModel(input_size_fraud)\n",
    "rnn_model_fraud = RNNModel(input_size_fraud)\n",
    "lstm_model_fraud = LSTMModel(input_size_fraud)\n",
    "\n",
    "mlp_model_credit = MLPModel(input_size_credit)\n",
    "cnn_model_credit = CNNModel(input_size_credit)\n",
    "rnn_model_credit = RNNModel(input_size_credit)\n",
    "lstm_model_credit = LSTMModel(input_size_credit)\n",
    "\n",
    "# LogisticRegression, RandomForest, GradientBoosting, DecisionTree\n",
    "logistic_fraud = LogisticRegression(max_iter=1000)\n",
    "rf_fraud = RandomForestClassifier(n_estimators=100)\n",
    "gb_fraud = GradientBoostingClassifier(n_estimators=100)\n",
    "dt_fraud = DecisionTreeClassifier()\n",
    "\n",
    "logistic_credit = LogisticRegression(max_iter=1000)\n",
    "rf_credit = RandomForestClassifier(n_estimators=100)\n",
    "gb_credit = GradientBoostingClassifier(n_estimators=100)\n",
    "dt_credit = DecisionTreeClassifier()\n",
    "\n",
    "# Set loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Train and evaluate each model for both fraud and credit data\n",
    "models = {\n",
    "    \"MLP_Fraud\": mlp_model_fraud,\n",
    "    \"CNN_Fraud\": cnn_model_fraud,\n",
    "    \"RNN_Fraud\": rnn_model_fraud,\n",
    "    \"LSTM_Fraud\": lstm_model_fraud,\n",
    "    \"MLP_Credit\": mlp_model_credit,\n",
    "    \"CNN_Credit\": cnn_model_credit,\n",
    "    \"RNN_Credit\": rnn_model_credit,\n",
    "    \"LSTM_Credit\": lstm_model_credit,\n",
    "    \"LogisticRegression_Fraud\": logistic_fraud,\n",
    "    \"RandomForest_Fraud\": rf_fraud,\n",
    "    \"GradientBoosting_Fraud\": gb_fraud,\n",
    "    \"DecisionTree_Fraud\": dt_fraud,\n",
    "    \"LogisticRegression_Credit\": logistic_credit,\n",
    "    \"RandomForest_Credit\": rf_credit,\n",
    "    \"GradientBoosting_Credit\": gb_credit,\n",
    "    \"DecisionTree_Credit\": dt_credit\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to save trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the models\n",
    "save_folder = 'C:/Users/Administrator/Documents/kifiya/Week_8/saved_models'\n",
    "os.makedirs(save_folder, exist_ok=True) \n",
    "\n",
    "# Function to save PyTorch models\n",
    "def save_pytorch_model(model, model_name):\n",
    "    save_path = os.path.join(save_folder, f'{model_name}.pt')\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f'{model_name} saved at {save_path}')\n",
    "\n",
    "# Function to save scikit-learn models\n",
    "def save_sklearn_model(model, model_name):\n",
    "    save_path = os.path.join(save_folder, f'{model_name}.joblib')\n",
    "    joblib.dump(model, save_path)\n",
    "    print(f'{model_name} saved at {save_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Evaluate and Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MLP_Fraud...\n",
      "Epoch [1/15], Loss: 0.5104\n",
      "Epoch [2/15], Loss: 0.4200\n",
      "Epoch [3/15], Loss: 0.3854\n",
      "Epoch [4/15], Loss: 0.3716\n",
      "Epoch [5/15], Loss: 0.3480\n",
      "Epoch [6/15], Loss: 0.3346\n",
      "Epoch [7/15], Loss: 0.3249\n",
      "Epoch [8/15], Loss: 0.3182\n",
      "Epoch [9/15], Loss: 0.3123\n",
      "Epoch [10/15], Loss: 0.3079\n",
      "Epoch [11/15], Loss: 0.3040\n",
      "Epoch [12/15], Loss: 0.2990\n",
      "Epoch [13/15], Loss: 0.2954\n",
      "Epoch [14/15], Loss: 0.2918\n",
      "Epoch [15/15], Loss: 0.2892\n",
      "Evaluating MLP_Fraud...\n",
      "Accuracy: 0.8816\n",
      "Precision: 0.8816\n",
      "Recall: 0.8816\n",
      "F1 Score: 0.8816\n",
      "MLP_Fraud saved at C:/Users/Administrator/Documents/kifiya/Week_8/saved_models\\MLP_Fraud.pt\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training CNN_Fraud...\n",
      "Epoch [1/15], Loss: 0.5665\n",
      "Epoch [2/15], Loss: 0.5344\n",
      "Epoch [3/15], Loss: 0.5200\n",
      "Epoch [4/15], Loss: 0.5080\n",
      "Epoch [5/15], Loss: 0.4982\n",
      "Epoch [6/15], Loss: 0.4906\n",
      "Epoch [7/15], Loss: 0.4839\n",
      "Epoch [8/15], Loss: 0.4791\n",
      "Epoch [9/15], Loss: 0.4740\n",
      "Epoch [10/15], Loss: 0.4701\n",
      "Epoch [11/15], Loss: 0.4660\n",
      "Epoch [12/15], Loss: 0.4633\n",
      "Epoch [13/15], Loss: 0.4596\n",
      "Epoch [14/15], Loss: 0.4566\n",
      "Epoch [15/15], Loss: 0.4532\n",
      "Evaluating CNN_Fraud...\n",
      "Accuracy: 0.7779\n",
      "Precision: 0.7781\n",
      "Recall: 0.7780\n",
      "F1 Score: 0.7779\n",
      "CNN_Fraud saved at C:/Users/Administrator/Documents/kifiya/Week_8/saved_models\\CNN_Fraud.pt\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training RNN_Fraud...\n",
      "Epoch [1/15], Loss: 0.5489\n",
      "Epoch [2/15], Loss: 0.4645\n",
      "Epoch [3/15], Loss: 0.4310\n",
      "Epoch [4/15], Loss: 0.4125\n",
      "Epoch [5/15], Loss: 0.4017\n",
      "Epoch [6/15], Loss: 0.3943\n",
      "Epoch [7/15], Loss: 0.3896\n",
      "Epoch [8/15], Loss: 0.3853\n",
      "Epoch [9/15], Loss: 0.3826\n",
      "Epoch [10/15], Loss: 0.3792\n",
      "Epoch [11/15], Loss: 0.3772\n",
      "Epoch [12/15], Loss: 0.3752\n",
      "Epoch [13/15], Loss: 0.3733\n",
      "Epoch [14/15], Loss: 0.3716\n",
      "Epoch [15/15], Loss: 0.3703\n",
      "Evaluating RNN_Fraud...\n",
      "Accuracy: 0.8331\n",
      "Precision: 0.8334\n",
      "Recall: 0.8332\n",
      "F1 Score: 0.8331\n",
      "RNN_Fraud saved at C:/Users/Administrator/Documents/kifiya/Week_8/saved_models\\RNN_Fraud.pt\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training LSTM_Fraud...\n",
      "Epoch [1/15], Loss: 0.5169\n",
      "Epoch [2/15], Loss: 0.4178\n",
      "Epoch [3/15], Loss: 0.3796\n",
      "Epoch [4/15], Loss: 0.3570\n",
      "Epoch [5/15], Loss: 0.3420\n",
      "Epoch [6/15], Loss: 0.3308\n",
      "Epoch [7/15], Loss: 0.3224\n",
      "Epoch [8/15], Loss: 0.3155\n",
      "Epoch [9/15], Loss: 0.3100\n",
      "Epoch [10/15], Loss: 0.3053\n",
      "Epoch [11/15], Loss: 0.3010\n",
      "Epoch [12/15], Loss: 0.2980\n",
      "Epoch [13/15], Loss: 0.2951\n",
      "Epoch [14/15], Loss: 0.2925\n",
      "Epoch [15/15], Loss: 0.2902\n",
      "Evaluating LSTM_Fraud...\n",
      "Accuracy: 0.8836\n",
      "Precision: 0.8838\n",
      "Recall: 0.8836\n",
      "F1 Score: 0.8836\n",
      "LSTM_Fraud saved at C:/Users/Administrator/Documents/kifiya/Week_8/saved_models\\LSTM_Fraud.pt\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training MLP_Credit...\n",
      "Epoch [1/15], Loss: 0.0332\n",
      "Epoch [2/15], Loss: 0.0165\n",
      "Epoch [3/15], Loss: 0.0139\n",
      "Epoch [4/15], Loss: 0.0126\n",
      "Epoch [5/15], Loss: 0.0125\n",
      "Epoch [6/15], Loss: 0.0129\n",
      "Epoch [7/15], Loss: 0.0120\n",
      "Epoch [8/15], Loss: 0.0119\n",
      "Epoch [9/15], Loss: 0.0117\n",
      "Epoch [10/15], Loss: 0.0122\n",
      "Epoch [11/15], Loss: 0.0119\n",
      "Epoch [12/15], Loss: 0.0106\n",
      "Epoch [13/15], Loss: 0.0167\n",
      "Epoch [14/15], Loss: 0.0123\n",
      "Epoch [15/15], Loss: 0.0106\n",
      "Early stopping triggered!\n",
      "Evaluating MLP_Credit...\n",
      "Accuracy: 0.9996\n",
      "Precision: 0.9996\n",
      "Recall: 0.9996\n",
      "F1 Score: 0.9996\n",
      "MLP_Credit saved at C:/Users/Administrator/Documents/kifiya/Week_8/saved_models\\MLP_Credit.pt\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training CNN_Credit...\n",
      "Epoch [1/15], Loss: 0.0420\n",
      "Epoch [2/15], Loss: 0.0222\n",
      "Epoch [3/15], Loss: 0.0181\n",
      "Epoch [4/15], Loss: 0.0167\n",
      "Epoch [5/15], Loss: 0.0149\n",
      "Epoch [6/15], Loss: 0.0149\n",
      "Epoch [7/15], Loss: 0.0142\n",
      "Epoch [8/15], Loss: 0.0139\n",
      "Epoch [9/15], Loss: 0.0136\n",
      "Epoch [10/15], Loss: 0.0135\n",
      "Epoch [11/15], Loss: 0.0136\n",
      "Epoch [12/15], Loss: 0.0133\n",
      "Epoch [13/15], Loss: 0.0131\n",
      "Epoch [14/15], Loss: 0.0129\n",
      "Epoch [15/15], Loss: 0.0127\n",
      "Evaluating CNN_Credit...\n",
      "Accuracy: 0.9989\n",
      "Precision: 0.9989\n",
      "Recall: 0.9989\n",
      "F1 Score: 0.9989\n",
      "CNN_Credit saved at C:/Users/Administrator/Documents/kifiya/Week_8/saved_models\\CNN_Credit.pt\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training RNN_Credit...\n",
      "Epoch [1/15], Loss: 0.0535\n",
      "Epoch [2/15], Loss: 0.0242\n",
      "Epoch [3/15], Loss: 0.0193\n",
      "Epoch [4/15], Loss: 0.0166\n",
      "Epoch [5/15], Loss: 0.0151\n",
      "Epoch [6/15], Loss: 0.0145\n",
      "Epoch [7/15], Loss: 0.0140\n",
      "Epoch [8/15], Loss: 0.0136\n",
      "Epoch [9/15], Loss: 0.0133\n",
      "Epoch [10/15], Loss: 0.0131\n",
      "Epoch [11/15], Loss: 0.0127\n",
      "Epoch [12/15], Loss: 0.0127\n",
      "Epoch [13/15], Loss: 0.0125\n",
      "Epoch [14/15], Loss: 0.0124\n",
      "Epoch [15/15], Loss: 0.0122\n",
      "Evaluating RNN_Credit...\n",
      "Accuracy: 0.9994\n",
      "Precision: 0.9995\n",
      "Recall: 0.9994\n",
      "F1 Score: 0.9994\n",
      "RNN_Credit saved at C:/Users/Administrator/Documents/kifiya/Week_8/saved_models\\RNN_Credit.pt\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training LSTM_Credit...\n",
      "Epoch [1/15], Loss: 0.0340\n",
      "Epoch [2/15], Loss: 0.0074\n",
      "Epoch [3/15], Loss: 0.0039\n",
      "Epoch [4/15], Loss: 0.0027\n",
      "Epoch [5/15], Loss: 0.0019\n",
      "Epoch [6/15], Loss: 0.0015\n",
      "Epoch [7/15], Loss: 0.0012\n",
      "Epoch [8/15], Loss: 0.0009\n",
      "Epoch [9/15], Loss: 0.0008\n",
      "Epoch [10/15], Loss: 0.0008\n",
      "Epoch [11/15], Loss: 0.0007\n",
      "Epoch [12/15], Loss: 0.0006\n",
      "Epoch [13/15], Loss: 0.0005\n",
      "Epoch [14/15], Loss: 0.0005\n",
      "Epoch [15/15], Loss: 0.0005\n",
      "Evaluating LSTM_Credit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 16:06:46 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'b22ca72d20354ad29f8e9147bd79da42', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9997\n",
      "Precision: 0.9997\n",
      "Recall: 0.9997\n",
      "F1 Score: 0.9997\n",
      "LSTM_Credit saved at C:/Users/Administrator/Documents/kifiya/Week_8/saved_models\\LSTM_Credit.pt\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training LogisticRegression_Fraud...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 16:06:58 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\Administrator\\miniconda3\\envs\\jojo\\lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "c:\\Users\\Administrator\\miniconda3\\envs\\jojo\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "2024/10/26 16:08:23 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\Administrator\\miniconda3\\envs\\jojo\\lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LogisticRegression_Fraud...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 16:08:30 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\Administrator\\miniconda3\\envs\\jojo\\lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2024/10/26 16:08:30 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'aff5a8988370455b8dc0c2229380fe5f', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6682\n",
      "Precision: 0.7110\n",
      "Recall: 0.6698\n",
      "F1 Score: 0.6517\n",
      "LogisticRegression_Fraud saved at C:/Users/Administrator/Documents/kifiya/Week_8/saved_models\\LogisticRegression_Fraud.joblib\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training RandomForest_Fraud...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 16:08:41 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\Administrator\\miniconda3\\envs\\jojo\\lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2024/10/26 16:10:05 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\Administrator\\miniconda3\\envs\\jojo\\lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RandomForest_Fraud...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 16:10:15 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\Administrator\\miniconda3\\envs\\jojo\\lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9672\n",
      "Precision: 0.9685\n",
      "Recall: 0.9674\n",
      "F1 Score: 0.9672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 16:10:15 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '393d7672255542a0afbb60ee4ac3cf34', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest_Fraud saved at C:/Users/Administrator/Documents/kifiya/Week_8/saved_models\\RandomForest_Fraud.joblib\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training GradientBoosting_Fraud...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 16:10:27 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\Administrator\\miniconda3\\envs\\jojo\\lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2024/10/26 16:11:39 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\Administrator\\miniconda3\\envs\\jojo\\lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating GradientBoosting_Fraud...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 16:11:47 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\Administrator\\miniconda3\\envs\\jojo\\lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2024/10/26 16:11:47 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '49223e0018d646508831bec2fbcbd8f3', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6645\n",
      "Precision: 0.6784\n",
      "Recall: 0.6654\n",
      "F1 Score: 0.6586\n",
      "GradientBoosting_Fraud saved at C:/Users/Administrator/Documents/kifiya/Week_8/saved_models\\GradientBoosting_Fraud.joblib\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training DecisionTree_Fraud...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 16:11:59 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\Administrator\\miniconda3\\envs\\jojo\\lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2024/10/26 16:12:06 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\Administrator\\miniconda3\\envs\\jojo\\lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating DecisionTree_Fraud...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 16:12:12 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\Administrator\\miniconda3\\envs\\jojo\\lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2024/10/26 16:12:12 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '9270785f953e4ddd81fd9b256945c27f', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9293\n",
      "Precision: 0.9297\n",
      "Recall: 0.9292\n",
      "F1 Score: 0.9292\n",
      "DecisionTree_Fraud saved at C:/Users/Administrator/Documents/kifiya/Week_8/saved_models\\DecisionTree_Fraud.joblib\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training LogisticRegression_Credit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\miniconda3\\envs\\jojo\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LogisticRegression_Credit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 16:13:16 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '3d4e528111dc4541903a4a92afa2790a', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9776\n",
      "Precision: 0.9778\n",
      "Recall: 0.9776\n",
      "F1 Score: 0.9776\n",
      "LogisticRegression_Credit saved at C:/Users/Administrator/Documents/kifiya/Week_8/saved_models\\LogisticRegression_Credit.joblib\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training RandomForest_Credit...\n",
      "Evaluating RandomForest_Credit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 16:21:29 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'b30a037ae47c46d0962eb413a21056c7', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9999\n",
      "Precision: 0.9999\n",
      "Recall: 0.9999\n",
      "F1 Score: 0.9999\n",
      "RandomForest_Credit saved at C:/Users/Administrator/Documents/kifiya/Week_8/saved_models\\RandomForest_Credit.joblib\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training GradientBoosting_Credit...\n",
      "Evaluating GradientBoosting_Credit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 16:34:55 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'acc9dfae32104e62aa7230bf8cb9f3b0', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9863\n",
      "Precision: 0.9864\n",
      "Recall: 0.9863\n",
      "F1 Score: 0.9863\n",
      "GradientBoosting_Credit saved at C:/Users/Administrator/Documents/kifiya/Week_8/saved_models\\GradientBoosting_Credit.joblib\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training DecisionTree_Credit...\n",
      "Evaluating DecisionTree_Credit...\n",
      "Accuracy: 0.9986\n",
      "Precision: 0.9986\n",
      "Recall: 0.9986\n",
      "F1 Score: 0.9986\n",
      "DecisionTree_Credit saved at C:/Users/Administrator/Documents/kifiya/Week_8/saved_models\\DecisionTree_Credit.joblib\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluating each model with MLflow tracking\n",
    "# Modify the existing model loop to include saving logic\n",
    "for model_name, model in models.items():\n",
    "    if isinstance(model, nn.Module):  # For PyTorch models\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "        train_model(model, train_loader_fraud if \"Fraud\" in model_name else train_loader_credit, optimizer, criterion)\n",
    "        print(f\"Evaluating {model_name}...\")\n",
    "        evaluate_model(model, test_loader_fraud if \"Fraud\" in model_name else test_loader_credit)\n",
    "        save_pytorch_model(model, model_name)  # Save PyTorch model\n",
    "        print('----------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    else:  # For scikit-learn models\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "        X_train = X_fraud_train_sci if \"Fraud\" in model_name else X_credit_train_sci\n",
    "        y_train = y_fraud_train_sci if \"Fraud\" in model_name else y_credit_train_sci\n",
    "        X_test = X_fraud_test_sci if \"Fraud\" in model_name else X_credit_test_sci\n",
    "        y_test = y_fraud_test_sci if \"Fraud\" in model_name else y_credit_test_sci\n",
    "        train_sklearn_model(model, X_train, y_train)\n",
    "        print(f\"Evaluating {model_name}...\")\n",
    "        evaluate_sklearn_model(model, X_test, y_test,model_name)\n",
    "        save_sklearn_model(model, model_name)  # Save scikit-learn model\n",
    "        print('-----------------------------------------------------------------------------------------------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jojo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
